---
spark_version: "2.1.0-bin-hadoop2.7"
spark_mirror: "http://d3kbcqa49mib13.cloudfront.net"
spark_dir: "/data/local/spark"
spark_src_dir: "/usr/local/src"
spark_conf_dir: "/etc/spark"
spark_usr_parent_dir: "/usr/lib"  #this is the folder where the spark archive will be extracted
spark_usr_dir: "/usr/lib/spark"   #this is the symlink to the extracted/installed spark
spark_lib_dir: "/var/lib/spark"
spark_log_dir: "/var/log/spark"
spark_run_dir: "/run/spark"
spark_user: "spark"           # the name of the (OS)user created for spark
spark_user_groups: [ users ]         # Optional list of (OS)groups the new spark user should belong to
spark_user_shell: "/bin/false"    # the spark user's default shell

spark_classpath_extras: [ aws-java-sdk-1.7.4.jar, hadoop-aws-2.7.3.jar ]
spark_env_extras: {}
spark_defaults_extras: {}
